{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QDfqAdNueZQk",
        "0tKF0-VCmabG",
        "DShDmnP_qqGg",
        "Sje4pbcMMcHj",
        "RwGE_XODMgjc",
        "SELKk1D1OTcO",
        "4ofpYxD9Ouxk",
        "Ny1oZnMhj1TD",
        "CEeiN1BtX6hV",
        "WmGsIMd2qrFv",
        "qDNKDrkdEh2Q",
        "FeoV7Qj2peRi",
        "roGxk_1r3mNV",
        "aw9T1Aew5Ynm",
        "HRicickuRTL9",
        "PXxQRb9qXTKA",
        "PAqw4cXbfHVg",
        "zmVSU8MuffTA",
        "RVNAGpDogp_h"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gus-oss/MachineLearning/blob/main/MachineLearningTarea5_Agrupamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning: Análisis y técnicas de machine learning de los datos sobre influenza, COVID-19 y otros virus respiratorios."
      ],
      "metadata": {
        "id": "cGFzsVHQlzoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paquetes por instalar"
      ],
      "metadata": {
        "id": "QDfqAdNueZQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn gower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_lj3ocXec5s",
        "outputId": "efe3826f-47d2-45e7-8d67-ed851eae5c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gower in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kB_28APli3Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Librerias y creación de carpeta de imagenes."
      ],
      "metadata": {
        "id": "iQCajMsZmFAP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsSfcDwylktS"
      },
      "outputs": [],
      "source": [
        "#Importamos las librerias que utilizaremos a lo largo del documento\n",
        "#import pandas as pd\n",
        "import numpy as np\n",
        "import statistics as stats   #utilizado en la parte estadistica descriptiva\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import statsmodels.api as sm\n",
        "import os #Se utilizo para guardar las imagenes (carpeta) y para guardar las imagenes en la carpeta\n",
        "import plotly.graph_objects as go #esta libreria es para hacer graficos dinamicos\n",
        "from statsmodels.graphics.gofplots import qqplot #se utilizo para hacer la grafica cuartil cuartil\n",
        "\n",
        "# Librerias para Machine Learning\n",
        "from sklearn.feature_selection import f_regression #para la seleccion de caracteristicas\n",
        "from sklearn.preprocessing import MinMaxScaler #para tener todas las variables entre 0 y 1\n",
        "from sklearn.feature_selection import VarianceThreshold #para la prueba de varianza\n",
        "from sklearn.feature_selection import mutual_info_regression #para la prueba de seleccion mutua\n",
        "from sklearn.linear_model import LinearRegression #regresion lineal simple\n",
        "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS #Hace toda la combinatoria\n",
        "#de las variables que tenemos en un conjunto de datos\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS #para la parte de sequential selector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN #para agrupación\n",
        "import gower #para dbscan con la metrica de gower\n",
        "from sklearn.neighbors import NearestNeighbors# para la grafica del codo\n",
        "from sklearn.metrics import silhouette_score #grafica del codo\n",
        "from sklearn.manifold import TSNE #vizualizacion de cluster\n",
        "from sklearn.decomposition import PCA #vizualizacion de cluster\n",
        "\n",
        "# Carpeta única para guardar las imágenes\n",
        "IMAGES_PATH = \"Galeria\"  # Nombre de la carpeta (puedes cambiarlo)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True) # Crea la carpeta si no existe\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"pdf\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Imagen guardada como \", fig_id, \"en la carpeta\", IMAGES_PATH) #Mensaje mas informativo\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "#Recomendación del Dr. Alberto Benavidez es generar imagenes en PDF para la creacion de articulos.\n",
        "#A demas de antes de llamar la función, escribir plt.tight_layout() para quitar espacios\n",
        "#inecesarios en las imagenes, este plt.tight_layout() ya se encuentra en la funcion pra guardar imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtencion de datos."
      ],
      "metadata": {
        "id": "0tKF0-VCmabG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos se actualizan cada cierto periodo de tiempo. Para esto, se automatizo la optención de los datos para que al momento de ejecutar el programa se estudien los datos mas recientes posibles publicados por la Direccion de Epidemiología de México."
      ],
      "metadata": {
        "id": "SlLXDv-ko8WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL de la página de datos abiertos\n",
        "url = 'https://www.gob.mx/salud/documentos/datos-abiertos-152127'\n",
        "\n",
        "# Obtener el HTML de la página\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Imprimir todos los enlaces en la página para ver su estructura\n",
        "print(\"Enlaces encontrados en la página:\")\n",
        "for a in soup.find_all('a', href=True):\n",
        "    print(a['href'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyfqSZO0nLZ5",
        "outputId": "8ceddc11-5d8e-48cd-915d-6383093dda25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enlaces encontrados en la página:\n",
            "/\n",
            "/tramites\n",
            "/gobierno\n",
            "/salud/en\n",
            "https://www.gob.mx/busqueda?utf8=✓\n",
            "?tab=\n",
            "/salud/es/archivo/prensa\n",
            "/salud/es/#390\n",
            "/salud/es/archivo/documentos\n",
            "/salud/es/archivo/acciones_y_programas\n",
            "/salud/es/archivo/multimedia\n",
            "http://portal.salud.gob.mx/sites/transparencia/transparencia/proteccion_datos/proteccion_1_1.html\n",
            "http://portal.salud.gob.mx/sites/transparencia/transparencia/transparencia/transparencia_1.html\n",
            "http://www.gob.mx\n",
            "/salud\n",
            "/salud/articulos/lavado-de-manos-esencial-en-la-prevencion-de-infecciones\n",
            "/salud/articulos/hospital-general-de-mexico-realiza-jornada-de-reconstruccion-mamaria-en-beneficio-de-mujeres-sobrevivientes-de-cancer\n",
            "/salud/articulos/secretaria-de-salud-reconoce-en-su-dia-a-sus-trabajadoras-y-trabajadores-por-su-esfuerzo-y-compromiso-con-el-pais\n",
            "/salud/articulos/gana-archivo-historico-de-la-secretaria-de-salud-premio-por-rescatar-y-conservar-documentos-relevantes-para-la-historia-de-mexico\n",
            "/salud/articulos/hospital-general-de-mexico-conmemora-el-dia-mundial-del-linfoma-y-refuerza-la-importancia-de-la-deteccion-oportuna\n",
            "https://www.gob.mx/salud/documentos/terminos-de-libre-uso-de-datos-abiertos-de-la-direccion-general-de-epidemiologia\n",
            "https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/datos_abiertos_influenza_covid19.zip\n",
            "https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/diccionario_datos_abiertos.zip\n",
            "https://www.gob.mx/salud/documentos/datos-abiertos-bases-historicas-direccion-general-de-epidemiologia\n",
            "https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/efe/datos_abiertos_efe.zip\n",
            "https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/efe/diccionario_datos_efe.zip\n",
            "https://www.gob.mx/salud/documentos/datos-abiertos-bases-historicas-de-enfermedades-febriles-exantematicas\n",
            "https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/etv/datos_abiertos_dengue.zip\n",
            "https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/etv/diccionario_datos_dengue.zip\n",
            "https://www.gob.mx/salud/documentos/datos-abiertos-bases-historicas-de-enfermedades-transmitidas-por-vector\n",
            "https://epidemiologia.salud.gob.mx/anuario/datos_abiertos/Anuario_2017.zip\n",
            "https://epidemiologia.salud.gob.mx/anuario/datos_abiertos/Anuario_2016.zip\n",
            "https://epidemiologia.salud.gob.mx/anuario/datos_abiertos/Anuario_2015.zip\n",
            "https://epidemiologia.salud.gob.mx/anuario/datos_abiertos/DiccionarioDatos.zip\n",
            "/cms/uploads/attachment/file/1026038/datos_abiertos_historicos_efe_2025.pdf\n",
            "/cms/uploads/attachment/file/965114/datos_abiertos_historicos_2024.pdf\n",
            "/cms/uploads/attachment/file/924585/datos_abiertos_2023_vinculo_zip.pdf\n",
            "/cms/uploads/attachment/file/830687/cierre_covid19__2022.pdf\n",
            "/cms/uploads/attachment/file/753707/Cierre_Datos_abiertos_historicos_2021.pdf\n",
            "/cms/uploads/attachment/file/753706/Cierre_Datos_abiertos_hist_ricos_2020.pdf\n",
            "https://www.facebook.com/sharer/sharer.php?u=https://www.gob.mx/salud/documentos/datos-abiertos-152127&src=sdkpreparse\n",
            "#\n",
            "https://datos.gob.mx/\n",
            "http://portal.salud.gob.mx/sites/transparencia/transparencia/transparencia/transparencia_1.html\n",
            "https://consultapublicamx.plataformadetransparencia.org.mx/vut-web/\n",
            "http://www.inai.org.mx/\n",
            "http://alertadores.funcionpublica.gob.mx/\n",
            "https://sidec.buengobierno.gob.mx/#!/\n",
            "/que-es-gobmx\n",
            "/salud/en\n",
            "/accesibilidad\n",
            "/terminos\n",
            "https://sidec.buengobierno.gob.mx/#!/\n",
            "https://www.facebook.com/gobmexico\n",
            "https://twitter.com/GobiernoMX\n",
            "https://www.instagram.com/gobmexico/\n",
            "https://www.youtube.com/@gobiernodemexico\n",
            "tel:+079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# URL del Diccionario de datos\n",
        "diccionario_url = 'https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/datos_abiertos_influenza_covid19.zip'\n",
        "\n",
        "# Descargar y abrir el archivo ZIP del Diccionario de datos\n",
        "diccionario_zip_response = requests.get(diccionario_url)\n",
        "diccionario_zip_response.raise_for_status()\n",
        "\n",
        "with zipfile.ZipFile(io.BytesIO(diccionario_zip_response.content)) as diccionario_zip:\n",
        "    # Listar los nombres de los archivos en el ZIP\n",
        "    print(\"Archivos contenidos en el ZIP del Diccionario de datos:\")\n",
        "    for file_name in diccionario_zip.namelist():\n",
        "        print(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "DOJ0f9zdqPSc",
        "outputId": "83ff3c68-5592-4cc5-a074-d574c2c47495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "HTTPSConnectionPool(host='datosabiertos.salud.gob.mx', port=443): Max retries exceeded with url: /gobmx/salud/datos_abiertos/datos_abiertos_influenza_covid19.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7931f410c2c0>: Failed to resolve 'datosabiertos.salud.gob.mx' ([Errno -3] Temporary failure in name resolution)\"))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_proxy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLSocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaierror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNameResolutionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7931f410c2c0>: Failed to resolve 'datosabiertos.salud.gob.mx' ([Errno -3] Temporary failure in name resolution)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreason\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='datosabiertos.salud.gob.mx', port=443): Max retries exceeded with url: /gobmx/salud/datos_abiertos/datos_abiertos_influenza_covid19.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7931f410c2c0>: Failed to resolve 'datosabiertos.salud.gob.mx' ([Errno -3] Temporary failure in name resolution)\"))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3400674066.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Descargar y abrir el archivo ZIP del Diccionario de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdiccionario_zip_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiccionario_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdiccionario_zip_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='datosabiertos.salud.gob.mx', port=443): Max retries exceeded with url: /gobmx/salud/datos_abiertos/datos_abiertos_influenza_covid19.zip (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7931f410c2c0>: Failed to resolve 'datosabiertos.salud.gob.mx' ([Errno -3] Temporary failure in name resolution)\"))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# URLs directas para los archivos ZIP\n",
        "covid_data_url = 'https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/datos_abiertos_influenza_covid19.zip'\n",
        "diccionario_url = 'https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/diccionario_datos_abiertos.zip'\n",
        "\n",
        "def descargar_datos_covid():\n",
        "    # Descargar y procesar el archivo ZIP de datos COVID-19\n",
        "    print(\"Descargando archivo ZIP de datos COVID-19 desde:\", covid_data_url)\n",
        "    covid_zip_response = requests.get(covid_data_url)\n",
        "    covid_zip_response.raise_for_status()\n",
        "\n",
        "    with zipfile.ZipFile(io.BytesIO(covid_zip_response.content)) as covid_zip:\n",
        "        for file_name in covid_zip.namelist():\n",
        "            if file_name.endswith('.csv'):\n",
        "                print(f\"Extrayendo {file_name}...\")\n",
        "                with covid_zip.open(file_name) as csv_file:\n",
        "                    df_covid = pd.read_csv(csv_file)\n",
        "                    print(\"Datos COVID-19 cargados correctamente en el DataFrame.\")\n",
        "                    break  # Salir después de encontrar el archivo CSV\n",
        "\n",
        "    # Descargar y procesar el archivo ZIP del Diccionario de datos\n",
        "    print(\"Descargando archivo ZIP del Diccionario de datos desde:\", diccionario_url)\n",
        "    diccionario_zip_response = requests.get(diccionario_url)\n",
        "    diccionario_zip_response.raise_for_status()\n",
        "\n",
        "    with zipfile.ZipFile(io.BytesIO(diccionario_zip_response.content)) as diccionario_zip:\n",
        "        # Cargar los archivos Excel\n",
        "        excel_file_catalogos = pd.read_excel(diccionario_zip.open('240708 Catalogos.xlsx'))\n",
        "        df_descriptores = pd.read_excel(diccionario_zip.open('240708 Descriptores_.xlsx'))\n",
        "        print(\"Archivos del Diccionario de datos cargados correctamente en DataFrames.\")\n",
        "\n",
        "        # Cargar hojas específicas en DataFrames separados\n",
        "        df_enti = pd.read_excel(diccionario_zip.open('240708 Catalogos.xlsx'), sheet_name='Catálogo de ENTIDADES')\n",
        "        df_muni = pd.read_excel(diccionario_zip.open('240708 Catalogos.xlsx'), sheet_name='Catálogo MUNICIPIOS')\n",
        "        df_sector = pd.read_excel(diccionario_zip.open('240708 Catalogos.xlsx'), sheet_name='Catálogo SECTOR')\n",
        "        df_pcr = pd.read_excel(diccionario_zip.open('240708 Catalogos.xlsx'), sheet_name='Catálogo RESULTADO_PCR')\n",
        "\n",
        "    return df_covid, excel_file_catalogos, df_descriptores, df_enti, df_muni, df_sector, df_pcr\n",
        "\n",
        "# Ejecutar la función y cargar los datos en los DataFrames\n",
        "df_covid, excel_file_catalogos, df_descriptores, df_enti, df_muni, df_sector, df_pcr = descargar_datos_covid()"
      ],
      "metadata": {
        "id": "Yd23wi3kqTaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_covid = pd.read_csv('/content/COVID19MEXICO.csv')\n",
        "#correr esta celda cuando el codigo de extraccion de datos automatico no funcione (que raro que siempre me pase en viernes)"
      ],
      "metadata": {
        "id": "lVic7zAkmTKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de la base de datos."
      ],
      "metadata": {
        "id": "DShDmnP_qqGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado nos encargaremos de checar valores nulos, formato de fechas, filas duplicadas y verificaremos errores al momento de capturar datos."
      ],
      "metadata": {
        "id": "43vsd2ErDuCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vizualisación de la base de datos"
      ],
      "metadata": {
        "id": "AASYu-pM_u-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid #visualizamos la base de datos"
      ],
      "metadata": {
        "id": "XQeezNtTqeYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qtWLMrUiruQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valores nulos"
      ],
      "metadata": {
        "id": "Sje4pbcMMcHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisión de valores faltantes (NaN)\n",
        "# Verificamos cuántos valores faltantes hay por columna\n",
        "valores_nulos = df_covid.isnull().sum()\n",
        "print(\"Valores faltantes por columna:\\n\", valores_nulos)"
      ],
      "metadata": {
        "id": "Sx1vOomuIoo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos encontrar que en el conjunto de datos no hay datos faltantes."
      ],
      "metadata": {
        "id": "6RYq_6lxI1EE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fortmato Fechas"
      ],
      "metadata": {
        "id": "RwGE_XODMgjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisión de tipos de datos\n",
        "# Convertimos las columnas de fecha a formato datetime para análisis temporal\n",
        "df_covid['FECHA_INGRESO']  = pd.to_datetime(\n",
        "    df_covid['FECHA_INGRESO'],\n",
        "    format=\"%Y-%m-%d\",\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "df_covid['FECHA_SINTOMAS'] = pd.to_datetime(\n",
        "    df_covid['FECHA_SINTOMAS'],\n",
        "    format=\"%Y-%m-%d\",\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "df_covid['FECHA_DEF']      = pd.to_datetime(\n",
        "    df_covid['FECHA_DEF'],\n",
        "    format=\"%Y-%m-%d\",\n",
        "    errors=\"coerce\"\n",
        ")"
      ],
      "metadata": {
        "id": "znOZTa__JV9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid[\"FECHA_INGRESO\"].unique() #NO CUENTA CON VALORES NaT"
      ],
      "metadata": {
        "id": "UySn3IE6LvBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid[\"FECHA_SINTOMAS\"].unique() #No cuenta con valores NaT"
      ],
      "metadata": {
        "id": "k8wHbb5wMJYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid[\"FECHA_DEF\"].unique()"
      ],
      "metadata": {
        "id": "GoRabocYMQDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al cambiar las fechas a datatime con el formato yyyy-mm-dd apreciamos que en la columna *FECHA_DEF* se encuentran valores NaT( conjunto original de datos se tenia como 9999-99-99, pero al hacer la conversion a datatime se colodaron NaT)  los cuales significan Not a Time, lo que quiere decir que no se tiene registro de fecha de defunción. Esto puede significar :\n",
        "\n",
        "\n",
        "*   el paciente fallecio y no se registro la fecha de defunción\n",
        "*   o el paciente no fallecio y se recupero\n",
        "\n",
        "Se investiga cuantos NaT se tienen registrados en el conjunto de datos."
      ],
      "metadata": {
        "id": "i5l4XCQtMShT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar los valores NaT en una columna específica\n",
        "nat_count_fecha_def = df_covid['FECHA_DEF'].isna().sum()\n",
        "print(f\"Valores NaT en la columna FECHA_DEF: {nat_count_fecha_def}\")"
      ],
      "metadata": {
        "id": "IOBddBl0NxXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de filas\n",
        "num_filas = df_covid.shape[0]\n",
        "print(f\"El DataFrame tiene {num_filas} filas.\")"
      ],
      "metadata": {
        "id": "3umPUNkZN547"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como el numero de NaT que hay en la columna FECHA_DEF es muy cercano al numero de filas que tiene el dataframe df_covid se opto por no eliminar las filas que tengan NaT y se conservaran."
      ],
      "metadata": {
        "id": "5M-Dau_oN8Ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Duplicados"
      ],
      "metadata": {
        "id": "SELKk1D1OTcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_filas_original = df_covid.shape[0]\n",
        "num_filas_unicas = df_covid.drop_duplicates().shape[0]\n",
        "print(f\"Total filas originales: {num_filas_original}\")\n",
        "print(f\"Total filas únicas: {num_filas_unicas}\")\n",
        "#En caso de encontrar filas duplicadas se tendria que utilizar df_covid = df_covid.drop_duplicates()"
      ],
      "metadata": {
        "id": "kHPwnrILOcoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se encontraron filas duplicadas en el conjunto de datos."
      ],
      "metadata": {
        "id": "kcq9KfHFOpjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**texto en negrita**### Edad"
      ],
      "metadata": {
        "id": "4ofpYxD9Ouxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid['EDAD'].unique()"
      ],
      "metadata": {
        "id": "LMQc5zcAPbG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que las edades estan correctas y que no hay errores de typing al momento de realizar la captura de las edades."
      ],
      "metadata": {
        "id": "jUO6JyKkPof_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnDDPV-7Wvrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estadistica Descriptiva."
      ],
      "metadata": {
        "id": "Ny1oZnMhj1TD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección realizaremos:\n",
        "\n",
        "- Comprobar si en el conjunto de datos son parametricos o no parametricos.\n",
        "- Calcular estadisticos descriptivos básicos.\n",
        "- Matriz de correlaciones.\n",
        "- Realizar pruebas de hipótesis a partir de las conclusiones obtenidas en la matriz de correlación.\n",
        "- Realizar graficos estadisticos."
      ],
      "metadata": {
        "id": "CNIBHJxbP258"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estadisticos."
      ],
      "metadata": {
        "id": "CEeiN1BtX6hV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos un analisis de los estadisticos de media, moda y mediana a la variable EDAD del conjunto de datos."
      ],
      "metadata": {
        "id": "kErBWaFVX-PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edades = df_covid['EDAD'].tolist()\n",
        "\n",
        "print(\"Promedio:\", stats.mean(edades))\n",
        "print(\"Mediana :\", stats.median(edades))\n",
        "print(\"Moda(s) :\", stats.multimode(edades))"
      ],
      "metadata": {
        "id": "L_e2hGWQQnNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La mayoría de los casos de COVID-19 en este conjunto de datos corresponden a adultos jóvenes (aproximadamente 37 años, mediana 35 años). Sin embargo, la moda de 1 año sugiere un pico artificial o un sesgo: podría reflejar una alta proporción de casos en menores de 1 año.\n",
        "\n",
        "Ahora realizamos un diagrama de cajas con vigotes para esta misma variable"
      ],
      "metadata": {
        "id": "Ky7_Ynw0aB8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina valores nulos si existen\n",
        "edades = df_covid['EDAD']\n",
        "\n",
        "plt.figure(figsize=(6, 8))\n",
        "plt.boxplot(edades, vert=False)\n",
        "plt.title('Distribución de la edad de pacientes COVID-19')\n",
        "plt.ylabel('Edad (años)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # líneas de referencia\n",
        "plt.show()\n",
        "\n",
        "\n",
        "save_fig(\"boxplot_edad\", fig_extension=\"pdf\")"
      ],
      "metadata": {
        "id": "BM_RQpzkZ1WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.violinplot(x=df_covid['EDAD'], color=\"skyblue\", inner=\"quartile\")\n",
        "plt.axvline(\n",
        "    x = stats.quantiles(df_covid['EDAD'], n=4)[0],\n",
        "    label = '$Q_1$',\n",
        "    linestyle = '--',\n",
        "    color = 'green'\n",
        ")\n",
        "plt.axvline(\n",
        "    x = stats.quantiles(df_covid['EDAD'], n=4)[1],\n",
        "    label = '$Q_2$',\n",
        "    linestyle = '-',\n",
        "    color = 'blue'\n",
        ")\n",
        "plt.axvline(\n",
        "    x = stats.quantiles(df_covid['EDAD'], n=4)[2],\n",
        "    label = '$Q_3$',\n",
        "    linestyle = '--',\n",
        "    color = 'green'\n",
        ")\n",
        "plt.legend()\n",
        "plt.title(\"Distribución de la edad de pacientes COVID-19\")\n",
        "plt.xlabel(\"Edad (años)\")\n",
        "\n",
        "# Guardar la figura\n",
        "save_fig(\"violinplot_edad\", fig_extension=\"pdf\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "57yhcXpJakHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafica Cuartil-cuartil de las edades del conjunto de datos del covid-19"
      ],
      "metadata": {
        "id": "jqbToM9vtBEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "qqplot(df_covid['EDAD'], line ='s')\n",
        "\n",
        "# Guardar la figura\n",
        "save_fig(\"cuartilcuartil_edad\", fig_extension=\"pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "huhUC7TctGBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo a la grafica, se sospecha que la muestra respecto a las edades no es parametrica."
      ],
      "metadata": {
        "id": "UAa0N1aTuOI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlaciones"
      ],
      "metadata": {
        "id": "WmGsIMd2qrFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid.columns"
      ],
      "metadata": {
        "id": "3IFVQHQ0qur_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_replace = [\n",
        "    'NEUMONIA', 'DIABETES', 'EPOC', 'ASMA', 'INMUSUPR',\n",
        "    'HIPERTENSION', 'CARDIOVASCULAR', 'OBESIDAD', 'RENAL_CRONICA'\n",
        "]\n",
        "\n",
        "for col in columns_to_replace:\n",
        "    df_covid[col] = df_covid[col].replace({'SI': 1}).astype('Int64')  # Usar 'Int64' para manejar valores nulos\n",
        "\n",
        "\n",
        "# Filtrar pacientes intubados\n",
        "df_covid19_intubado = df_covid[df_covid['INTUBADO'] == 1]  # Usamos 1 para \"Sí\"\n",
        "\n",
        "# Seleccionar las columnas de interés\n",
        "df_covid19_resultado = df_covid19_intubado[['OBESIDAD', 'NEUMONIA', 'EDAD',\n",
        "                                                'NACIONALIDAD', 'EMBARAZO', 'INDIGENA', 'DIABETES',\n",
        "                                                'EPOC', 'ASMA', 'INMUSUPR', 'HIPERTENSION', 'OTRA_COM',\n",
        "                                                'CARDIOVASCULAR', 'RENAL_CRONICA', 'TABAQUISMO', 'OTRO_CASO']]\n",
        "\n",
        "# Reemplazar valores específicos por NaN\n",
        "df_covid19V2_resultado = df_covid19_resultado.replace(['Se ignora', 'No Aplica', 'No especificado'], np.nan)\n",
        "\n",
        "# Eliminar filas con valores NaN\n",
        "df_covid19V2_resultado_clean = df_covid19_resultado.dropna()\n",
        "\n",
        "# Crear el heatmap de correlación\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_covid19V2_resultado_clean.corr(), annot=True,annot_kws={\"size\": 8}, fmt=\".2f\", cmap=\"coolwarm\", linewidths=.5)\n",
        "plt.title('Correlación de Condiciones en Pacientes Intubados de virus respiratorios')\n",
        "save_fig('Correlacion_Condiciones_Pacientes_Intubados_COVID19' , fig_extension=\"pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PlEbRGfSzIJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_LruJEszk2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruebas de hipotesis"
      ],
      "metadata": {
        "id": "6pB2edMZDivM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Primera prueba de hipotesis"
      ],
      "metadata": {
        "id": "YUKHuNWiDmx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selección de Caracteristicas"
      ],
      "metadata": {
        "id": "qDNKDrkdEh2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado realizaremos:\n",
        "\n",
        "- Aplicar algún método de filtro a tus datos mediante el uso de SelectKBest\n",
        "- Aplicar los modelos de selección de características cuidando los supuestos de cada modelo\n",
        "- Busca una o varias métricas para seleccionar características en literatura relacionada del problema.\n",
        "- Con base en tu investigación, determina las características más relevantes de tu conjunto de datos."
      ],
      "metadata": {
        "id": "r0zR2WDHo5xZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separacion de las columnas."
      ],
      "metadata": {
        "id": "FeoV7Qj2peRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos interesara saber si un paciente da positivo a SARS-CoV-2, por ese motivo, elegimos la variable dependiente\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "y = df_covid[[\"CLASIFICACION_FINAL_COVID\"]]\n",
        "```\n",
        "\n",
        "Mientras que las demas variables del conjunto de datos seran nuestras variables independientes\n",
        "\n",
        "```\n",
        "x = df_covid[[ 'EDAD', 'NEUMONIA',\n",
        "              'EMBARAZO', 'DIABETES', 'EPOC', 'ASMA',\n",
        "              'INMUSUPR', 'HIPERTENSION', 'CARDIOVASCULAR', 'OBESIDAD', 'RENAL_CRONICA', 'TABAQUISMO']]\n",
        "```\n"
      ],
      "metadata": {
        "id": "3B8Gk368pkub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encontramos si hay linealidad entre las columnas independientes y dependientes"
      ],
      "metadata": {
        "id": "u-5Xefjl1oXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid_dropna = df_covid.dropna()\n",
        "y = df_covid_dropna[[\"CLASIFICACION_FINAL_COVID\"]]\n",
        "x = df_covid_dropna[[ 'EDAD', 'NEUMONIA','EMBARAZO', 'DIABETES', 'EPOC', 'ASMA',\n",
        "                      'INMUSUPR', 'HIPERTENSION', 'CARDIOVASCULAR', 'OBESIDAD', 'RENAL_CRONICA', 'TABAQUISMO']]"
      ],
      "metadata": {
        "id": "Nj1OyPAOqNmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valor_f = f_regression(x,y)\n",
        "valor_f"
      ],
      "metadata": {
        "id": "aHpVprcnw070"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea un arreglo para identificar cuales variables pasan la prueba de linealidad\n",
        "pasan_prueba = []\n",
        "no_pasan_prueba=[]\n",
        "alpha = 0.05\n",
        "\n",
        "for i in range (len(valor_f[0])):\n",
        "  if valor_f[0][i] < alpha:\n",
        "    pasan_prueba.append(x.columns[i])\n",
        "  else:\n",
        "    no_pasan_prueba.append(x.columns[i])"
      ],
      "metadata": {
        "id": "V4cQ3ns9w7Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pasan_prueba"
      ],
      "metadata": {
        "id": "HqkgYwSwyS6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resultados = pd.DataFrame(valor_f[0], index = x.columns, columns= ['valor_f']).sort_values('valor_f', ascending = True)\n",
        "df_resultados"
      ],
      "metadata": {
        "id": "jGiGZUBCycR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(df_resultados.index, df_resultados.valor_f)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N_dvjS9yyt9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Umbral de varianza"
      ],
      "metadata": {
        "id": "roGxk_1r3mNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esto, tenemos que normalizar las variables."
      ],
      "metadata": {
        "id": "zXyphbpj3qCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "escalador = MinMaxScaler()\n",
        "escala = escalador.fit_transform(x)\n",
        "x_escalada = pd.DataFrame(escala, columns=x.columns)\n",
        "x_escalada"
      ],
      "metadata": {
        "id": "FLKvkASy165c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez obtenida las variables normalizadas, obtenemos las varianzas"
      ],
      "metadata": {
        "id": "jFMS4e4j4k6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selector = VarianceThreshold()\n",
        "selector.fit_transform(x_escalada)\n",
        "selector.variances_"
      ],
      "metadata": {
        "id": "7oj1AlU84pdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resultados['varianza'] = selector.variances_\n",
        "df_resultados"
      ],
      "metadata": {
        "id": "kwZ8PCFs41OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(df_resultados.index, df_resultados.varianza)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P4PIVxs35BmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Información mutua"
      ],
      "metadata": {
        "id": "aw9T1Aew5Ynm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos permite encontrar relacions no lineales entre los datos"
      ],
      "metadata": {
        "id": "Jk90wqMR5f0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mi = mutual_info_regression(x,y)\n",
        "mi"
      ],
      "metadata": {
        "id": "VVwe8fw65NAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resultados['mi'] = mi\n",
        "df_resultados"
      ],
      "metadata": {
        "id": "lCGDh45PPY0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(df_resultados.index, df_resultados.mi)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4rgpR1sIPoSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados de variables dependientes en manera no lineal"
      ],
      "metadata": {
        "id": "6jP6oIOiQs7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reresion lineal"
      ],
      "metadata": {
        "id": "HRicickuRTL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr"
      ],
      "metadata": {
        "id": "bwSk1hCUQlfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efs = EFS(estimator = lr,   #use linear regression as the classifier/estimator\n",
        "          min_features = 1, #the minimum number of features to consider is 1\n",
        "          max_features = 5, # the maximum number of features to consider is 4\n",
        "          scoring = 'neg_mean_absolute_error', #The metric to use to evluate the classifier is accuracy\n",
        "          cv = 5)"
      ],
      "metadata": {
        "id": "bAELV4XXRqZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efs = efs.fit(x,y)"
      ],
      "metadata": {
        "id": "RmZJGK__S4Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efs.best_score_"
      ],
      "metadata": {
        "id": "zvws8Q9sS-g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#la mejor combinacion de la tabla es\n",
        "efs.best_feature_names_\n"
      ],
      "metadata": {
        "id": "jaabV-0rTkCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resultados_efs = pd.DataFrame(efs.get_metric_dict()).T\n",
        "df_resultados_efs = df_resultados_efs.sort_values('avg_score', ascending = False)\n",
        "df_resultados_efs"
      ],
      "metadata": {
        "id": "Bg6HzDXGTWkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.plot(\n",
        "    df_resultados_efs.iloc[:5].feature_names.astype(str),\n",
        "    df_resultados_efs.iloc[:5].avg_score\n",
        "\n",
        ")\n",
        "#plt.gca().invert_yaxis()\n",
        "plt.xticks(rotation = 90)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "TLTBXaUsUxOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "queremos el mas cercano al cero para considerar la mejor"
      ],
      "metadata": {
        "id": "yU6zLFz1XKXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequencial Feature Selector"
      ],
      "metadata": {
        "id": "PXxQRb9qXTKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sfs = SFS(\n",
        "    estimator = lr,\n",
        "    k_features = (1,5),\n",
        "    forward = True,\n",
        "    scoring = 'neg_mean_absolute_error',\n",
        "    cv=5\n",
        ")"
      ],
      "metadata": {
        "id": "Jlo7vixNV5kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs = sfs.fit(x,y)"
      ],
      "metadata": {
        "id": "sbTRb0cpaEEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs.k_feature_names_"
      ],
      "metadata": {
        "id": "8tH2T8HBaHmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sfs.subsets_).T.sort_values('avg_score', ascending = False)"
      ],
      "metadata": {
        "id": "OMkeA3r4abeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las variables que mas contribuyen son la edad y el embarazo"
      ],
      "metadata": {
        "id": "eiP9q6qTavIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid"
      ],
      "metadata": {
        "id": "4Gp971CTahKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WTOjwypUATr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid.columns"
      ],
      "metadata": {
        "id": "p5tF6BGkBcPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agrupación"
      ],
      "metadata": {
        "id": "PAqw4cXbfHVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtrado"
      ],
      "metadata": {
        "id": "zmVSU8MuffTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filtrado de las variables categoricas\n",
        "# Lista de columnas seleccionadas\n",
        "columnas_gow = [\n",
        " 'SECTOR', 'ENTIDAD_UM', 'SEXO', 'ENTIDAD_NAC', 'ENTIDAD_RES', 'MUNICIPIO_RES',\n",
        " 'TIPO_PACIENTE', 'INTUBADO', 'NEUMONIA', 'EDAD', 'NACIONALIDAD',\n",
        " 'EMBARAZO', 'HABLA_LENGUA_INDIG', 'INDIGENA', 'DIABETES', 'EPOC', 'ASMA',\n",
        " 'INMUSUPR', 'HIPERTENSION', 'OTRA_COM', 'CARDIOVASCULAR', 'OBESIDAD',\n",
        " 'RENAL_CRONICA', 'TABAQUISMO', 'OTRO_CASO', 'TOMA_MUESTRA_LAB',\n",
        " 'RESULTADO_PCR', 'RESULTADO_PCR_COINFECCION', 'TOMA_MUESTRA_ANTIGENO',\n",
        " 'RESULTADO_ANTIGENO', 'UCI'\n",
        "]\n",
        "\n",
        "# Filtramos el dataset original\n",
        "df_gow = df_covid[columnas_gow + ['CLASIFICACION_FINAL_COVID']].sample(n=20000, random_state=42).copy()\n",
        "\n",
        "#Seleccionamos una muestra del total de filas, debido a que  Gower aumenta al cuadrado de el numero de filas\n",
        "#por ende no podre poner todas, gano la batalla pero no al guerra"
      ],
      "metadata": {
        "id": "FFUrPu4efNzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DBSCAN + Gower"
      ],
      "metadata": {
        "id": "RVNAGpDogp_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos todas las columnas numéricas a float\n",
        "df_gow = df_gow.astype(float)\n",
        "\n",
        "# Calculamos la matriz de distancias de Gower\n",
        "dist_gower = gower.gower_matrix(df_gow)"
      ],
      "metadata": {
        "id": "jY3_gA41goUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determinamos eps y min_sample optimos para DBSCAN, de acuerdo a las buenas practicas de https://stataiml.com/posts/how_to_set_dbscan_paramter/"
      ],
      "metadata": {
        "id": "75bWN6Jgl8Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" BÚSQUEDA DE PARÁMETROS ÓPTIMOS PARA DBSCAN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "#DETERMINAR MIN_SAMPLES BASADO EN DIMENSIONALIDAD\n",
        "n_features = len(columnas_gow)  # 32 columnas\n",
        "n_samples = len(df_gow)  # 20,000 filas\n",
        "\n",
        "print(f\"\\n INFORMACIÓN DEL DATASET:\")\n",
        "print(f\"   • Número de características (dimensiones): {n_features}\")\n",
        "print(f\"   • Número de muestras: {n_samples:,}\")\n",
        "\n",
        "# Reglas para MinPts según la literatura:\n",
        "min_pts_candidates = {\n",
        "    'Regla 1 (= dimensionalidad)': n_features,\n",
        "    'Regla 2 (2 * dimensionalidad)': 2 * n_features,\n",
        "    'Regla 3 (conservador para ruido)': int(2.5 * n_features),\n",
        "    'Regla 4 (muy conservador)': int(3 * n_features)\n",
        "}\n",
        "\n",
        "print(f\"\\n CANDIDATOS PARA MIN_SAMPLES:\")\n",
        "print(\"-\" * 60)\n",
        "for regla, valor in min_pts_candidates.items():\n",
        "    print(f\"   • {regla}: {valor}\")\n",
        "\n",
        "#FUNCIÓN PARA DETECTAR EL CODO (KNEE/ELBOW)\n",
        "def detectar_codo(x, y):\n",
        "    \"\"\"\n",
        "    Detecta el punto del codo usando el método de la máxima curvatura.\n",
        "    \"\"\"\n",
        "    # Normalizamos los datos\n",
        "    x_norm = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
        "    y_norm = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
        "\n",
        "    # Calculamos la línea que conecta el primer y último punto\n",
        "    p1 = np.array([x_norm[0], y_norm[0]])\n",
        "    p2 = np.array([x_norm[-1], y_norm[-1]])\n",
        "\n",
        "    # Calculamos la distancia perpendicular de cada punto a esta línea\n",
        "    distancias = []\n",
        "    for i in range(len(x_norm)):\n",
        "        p = np.array([x_norm[i], y_norm[i]])\n",
        "        # Distancia del punto a la línea\n",
        "        d = np.abs(np.cross(p2-p1, p1-p)) / np.linalg.norm(p2-p1)\n",
        "        distancias.append(d)\n",
        "\n",
        "    # El codo es donde la distancia es máxima\n",
        "    knee_idx = np.argmax(distancias)\n",
        "\n",
        "    return knee_idx, y[knee_idx]\n",
        "\n",
        "# MÉTODO K-NN PARA ENCONTRAR EPS ÓPTIMO\n",
        "print(f\"\\n\\n CALCULANDO DISTANCIAS K-NN PARA CADA CANDIDATO...\\n\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "resultados_eps = {}\n",
        "idx = 0\n",
        "\n",
        "for nombre_regla, k_value in min_pts_candidates.items():\n",
        "    print(f\"Procesando k = {k_value} ({nombre_regla})...\")\n",
        "\n",
        "    # Calculamos distancias al k-ésimo vecino más cercano\n",
        "    k_distances = []\n",
        "\n",
        "    for i in range(len(dist_gower)):\n",
        "        # Obtenemos las distancias ordenadas (excluyendo la distancia a sí mismo)\n",
        "        distances = np.sort(dist_gower[i])[1:k_value+1]\n",
        "        # Guardamos la distancia al k-ésimo vecino\n",
        "        k_distances.append(distances[-1])\n",
        "\n",
        "    # Ordenamos las distancias\n",
        "    k_distances_sorted = np.sort(k_distances)\n",
        "\n",
        "    # Detectamos el codo automáticamente\n",
        "    x_vals = np.arange(len(k_distances_sorted))\n",
        "    knee_idx, eps_optimo = detectar_codo(x_vals, k_distances_sorted)\n",
        "\n",
        "    # También calculamos percentiles como referencia\n",
        "    eps_p90 = np.percentile(k_distances_sorted, 90)\n",
        "    eps_p95 = np.percentile(k_distances_sorted, 95)\n",
        "    eps_p98 = np.percentile(k_distances_sorted, 98)\n",
        "\n",
        "    # Guardamos resultados\n",
        "    resultados_eps[k_value] = {\n",
        "        'nombre': nombre_regla,\n",
        "        'eps_knee': eps_optimo,\n",
        "        'eps_p90': eps_p90,\n",
        "        'eps_p95': eps_p95,\n",
        "        'eps_p98': eps_p98,\n",
        "        'knee_idx': knee_idx,\n",
        "        'k_distances': k_distances_sorted\n",
        "    }\n",
        "\n",
        "    # Graficamos\n",
        "    axes[idx].plot(k_distances_sorted, linewidth=2, color='steelblue', label='Distancias k-NN')\n",
        "\n",
        "    # Marcamos el codo detectado\n",
        "    axes[idx].scatter([knee_idx], [eps_optimo], color='red', s=200, zorder=5,\n",
        "                      marker='*', edgecolors='black', linewidths=2,\n",
        "                      label=f'Codo detectado')\n",
        "    axes[idx].axhline(y=eps_optimo, color='red', linestyle='--', linewidth=2,\n",
        "                      label=f'Knee/Elbow: {eps_optimo:.4f}')\n",
        "    axes[idx].axhline(y=eps_p90, color='orange', linestyle=':', alpha=0.7,\n",
        "                      label=f'P90: {eps_p90:.4f}')\n",
        "    axes[idx].axhline(y=eps_p95, color='green', linestyle=':', alpha=0.7,\n",
        "                      label=f'P95: {eps_p95:.4f}')\n",
        "\n",
        "    axes[idx].set_xlabel('Puntos ordenados por distancia', fontsize=11, fontweight='bold')\n",
        "    axes[idx].set_ylabel(f'Distancia al {k_value}-ésimo vecino', fontsize=11, fontweight='bold')\n",
        "    axes[idx].set_title(f'k = {k_value}\\n{nombre_regla}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "    axes[idx].legend(loc='upper left', fontsize=8)\n",
        "\n",
        "    # Zoom en la región del codo\n",
        "    if eps_optimo < np.max(k_distances_sorted) * 0.5:\n",
        "        axes[idx].set_ylim([0, np.percentile(k_distances_sorted, 99)])\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# Guardamos la figura con la función personalizada\n",
        "save_fig('dbscan_knn_distance_optimal_eps', tight_layout=True, fig_extension=\"pdf\", resolution=300)\n",
        "plt.show()\n",
        "\n",
        "# RESUMEN DE VALORES ÓPTIMOS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN DE VALORES EPS ÓPTIMOS POR MIN_SAMPLES\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Min_Samples':<15} {'Eps (Knee)':<15} {'Eps (P90)':<15} {'Eps (P95)':<15} {'Regla'}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for k_value, datos in resultados_eps.items():\n",
        "    print(f\"{k_value:<15} {datos['eps_knee']:<15.4f} {datos['eps_p90']:<15.4f} \"\n",
        "          f\"{datos['eps_p95']:<15.4f} {datos['nombre'][:30]}\")\n",
        "\n",
        "# EVALUACIÓN DE LAS MEJORES COMBINACIONES\n",
        "print(\"\\n\\n EVALUANDO CALIDAD DE CLUSTERING CON LAS COMBINACIONES ÓPTIMAS...\\n\")\n",
        "\n",
        "evaluaciones = []\n",
        "\n",
        "for k_value, datos in resultados_eps.items():\n",
        "    # Probamos con el eps del knee y los percentiles\n",
        "    for eps_tipo, eps_valor in [('Knee', datos['eps_knee']),\n",
        "                                 ('P90', datos['eps_p90']),\n",
        "                                 ('P95', datos['eps_p95'])]:\n",
        "\n",
        "        # Aplicamos DBSCAN\n",
        "        db_temp = DBSCAN(metric=\"precomputed\", eps=eps_valor, min_samples=k_value)\n",
        "        labels = db_temp.fit_predict(dist_gower)\n",
        "\n",
        "        # Métricas\n",
        "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "        n_noise = list(labels).count(-1)\n",
        "        pct_noise = (n_noise / len(labels)) * 100\n",
        "\n",
        "        # Calculamos silhouette si es posible\n",
        "        silhouette = None\n",
        "        if n_clusters >= 2 and n_noise < len(labels):\n",
        "            mask = labels != -1\n",
        "            if sum(mask) > 10:\n",
        "                try:\n",
        "                    silhouette = silhouette_score(dist_gower[mask][:, mask],\n",
        "                                                   labels[mask],\n",
        "                                                   metric='precomputed')\n",
        "                except:\n",
        "                    silhouette = None\n",
        "\n",
        "        evaluaciones.append({\n",
        "            'min_samples': k_value,\n",
        "            'eps': eps_valor,\n",
        "            'eps_tipo': eps_tipo,\n",
        "            'n_clusters': n_clusters,\n",
        "            'n_noise': n_noise,\n",
        "            'pct_noise': pct_noise,\n",
        "            'silhouette': silhouette,\n",
        "            'regla': datos['nombre']\n",
        "        })\n",
        "\n",
        "# Convertimos a DataFrame y mostramos resultados\n",
        "import pandas as pd\n",
        "df_eval = pd.DataFrame(evaluaciones)\n",
        "\n",
        "# Filtramos solo resultados válidos (con clusters y no demasiado ruido)\n",
        "df_eval_validos = df_eval[(df_eval['n_clusters'] >= 2) & (df_eval['pct_noise'] < 50)].copy()\n",
        "\n",
        "if len(df_eval_validos) > 0:\n",
        "    # Ordenamos por menor ruido y luego por mayor silhouette\n",
        "    df_eval_validos = df_eval_validos.sort_values(\n",
        "        by=['pct_noise', 'silhouette'],\n",
        "        ascending=[True, False]\n",
        "    )\n",
        "\n",
        "    print(\" TOP 10 MEJORES CONFIGURACIONES:\")\n",
        "    print(\"=\"*100)\n",
        "    print(df_eval_validos[['min_samples', 'eps', 'eps_tipo', 'n_clusters', 'pct_noise', 'silhouette']].head(10).to_string(index=False))\n",
        "\n",
        "    # Mejor configuración\n",
        "    mejor = df_eval_validos.iloc[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" CONFIGURACIÓN ÓPTIMA RECOMENDADA\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\n PARÁMETROS:\")\n",
        "    print(f\"   min_samples = {int(mejor['min_samples'])}\")\n",
        "    print(f\"   eps = {mejor['eps']:.4f} (método: {mejor['eps_tipo']})\")\n",
        "    print(f\"\\n RESULTADOS ESPERADOS:\")\n",
        "    print(f\"   • Número de clusters: {int(mejor['n_clusters'])}\")\n",
        "    print(f\"   • Puntos de ruido: {int(mejor['n_noise'])} ({mejor['pct_noise']:.2f}%)\")\n",
        "    if mejor['silhouette'] is not None:\n",
        "        print(f\"   • Silhouette Score: {mejor['silhouette']:.4f}\")\n",
        "    print(f\"   • Basado en: {mejor['regla']}\")\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "id": "ZsN-neBS0NZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustamos el modelo DBSCAN usando la matriz de Gower\n",
        "db = DBSCAN(metric=\"precomputed\", eps=0.0605, min_samples=93) #eps = radio de la vecindad, min_samples indica cuantos punto tiene que tener como minimo un clouster\n",
        "#esto despues se mejorara para encontrar el mejor eps\n",
        "db.fit(dist_gower)\n",
        "\n",
        "# Guardamos los clusters en un nuevo DataFrame\n",
        "df_gow['cluster'] = db.labels_"
      ],
      "metadata": {
        "id": "L-Hd0R3ZhHou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos resultados\n",
        "df_gow['cluster'].unique()"
      ],
      "metadata": {
        "id": "m_M7RAcQk_yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Clusters encontrados: {len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)}\")\n",
        "print(f\"Puntos de ruido: {list(db.labels_).count(-1)}\")"
      ],
      "metadata": {
        "id": "x8QRRbSOlAXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apreciamos que el algoritmo detecta 220 puntos de ruido, en proporcion respecto a mis 20,000 datos muestrales equivale al 1.1% lo cual esta en el rango aceptable. Visualizaremos ahora los clousters junto con el ruido"
      ],
      "metadata": {
        "id": "vs7YutUGp1ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "# --- OPCIÓN 1: PCA para exploracion ---\n",
        "#pca = PCA(n_components=2, random_state=42)\n",
        "#coords_pca = pca.fit_transform(dist_gower)\n",
        "\n",
        "# --- OPCIÓN 2: t-SNE para grafico final ---\n",
        "tsne = TSNE(n_components=2, metric=\"precomputed\", random_state=42, perplexity=30, init=\"random\")\n",
        "coords_tsne = tsne.fit_transform(dist_gower)\n",
        "\n",
        "# Elegimos una opción para graficar:\n",
        "coords = coords_tsne #coords_pca  # o coords_tsne si usas t-SNE\n",
        "\n",
        "# Agregamos coordenadas al DataFrame\n",
        "df_gow['x'] = coords[:, 0]\n",
        "df_gow['y'] = coords[:, 1]\n",
        "\n",
        "# --- Graficamos ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    data=df_gow,\n",
        "    x='x', y='y',\n",
        "    hue='cluster',\n",
        "    palette='tab10',  # paleta de colores\n",
        "    s=15,\n",
        "    alpha=0.8,\n",
        "    edgecolor=None\n",
        ")\n",
        "plt.title('Visualización de Clusters DBSCAN (distancia de Gower)')\n",
        "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "save_fig(\"clusters_dbscan_gower\", fig_extension=\"pdf\", resolution=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UKs5zJZDqMYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}